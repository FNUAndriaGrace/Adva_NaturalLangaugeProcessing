# üß† Advanced Natural Language Processing

This repository contains coursework and a final project from the graduate-level **Advanced Natural Language Processing** course. It includes hands-on implementation of LSTMs, BERT, Transformers, and sequence-to-sequence architectures for classification, summarization, and text generation.

---

## üìÇ Projects & Assignments

### `ADV_NLP-1_Andria.ipynb`
- **Objective:** Basic NLP using RNNs or LSTMs for classification or sequence modeling.
- **Model:** Recurrent Neural Network (e.g., LSTM).
- **Dataset:** Introductory NLP corpus (classification or language modeling).
- **Result:** Validates RNN performance on toy datasets.

### `Assignment1_Question2_Andria-1.ipynb`
- **Objective:** Text classification (e.g., sentiment/intent) using neural networks.
- **Model:** LSTM or GRU with embeddings.
- **Dataset:** Standard classification dataset (e.g., IMDB).
- **Metric:** Accuracy; model achieves ~80‚Äì90%.

### `Assignment2_Question1_Andria-1.ipynb`
- **Objective:** Sequence modeling (e.g., summarization or QA).
- **Model:** Seq2Seq or fine-tuned transformer.
- **Dataset:** Summary or inference dataset (e.g., SNLI, CNN/DailyMail).
- **Metric:** BLEU/ROUGE or classification accuracy.

### `Assignment_3_part_1_AndriaGrace.ipynb`
- **Objective:** Literature survey and proposal for final project.
- **Content:** Compared baseline models and datasets from recent NLP papers.

### `Assignment_3_part_2_AndriaGrace.ipynb`
- **Objective:** Reproduce a published NLP baseline model.
- **Model:** Transformer or pretrained language model (e.g., BERT).
- **Dataset:** Same as original paper (e.g., SQuAD, WMT).
- **Metric:** Matched BLEU, F1, or accuracy from baseline paper.

###  `final_ANLP_APJ.ipynb`
- **Objective:** Final project on **Emotion Detection in Text** using advanced NLP models with a deployed UI.
- **Model:** Fine-tuned BERT and LSTM models for multi-class emotion classification.
- **Dataset:** Emotion-labeled dataset (e.g., Saravia‚Äôs dataset ‚Äì joy, anger, fear, etc.).
- **UI Feature:** Built a web interface where users enter text and receive real-time emotion predictions.
- **Metric:** High accuracy and F1-score; BERT significantly outperformed baseline.
- **Highlight:** Integrated a transformer-based classifier with a full-stack deployment for real-world usability.

---

## üß† Key Topics

- Text Classification
- Sequence-to-Sequence Modeling
- Transfer Learning (BERT, Transformers)
- Summarization & Generation
- Deployment & UI Integration
- Evaluation Metrics: Accuracy, BLEU, ROUGE, F1

---

## üõ†Ô∏è Tools & Libraries

- Python, PyTorch, TensorFlow
- HuggingFace Transformers, Streamlit/Flask (for UI)
- NumPy, Pandas, Matplotlib, Seaborn

---

_This repository showcases practical mastery of advanced NLP techniques, real-time emotion detection, and full-stack model deployment._

